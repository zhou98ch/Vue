{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b7d7777",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71d822d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3368b1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model 1 imports\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bd3cb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7d285081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(151444, 72, 32)\n"
     ]
    }
   ],
   "source": [
    "#model 2 get inputs both_vectors\n",
    "with open('new_both_vectors.dat','rb')as file: \n",
    "    both_vectors=pickle.load(file)\n",
    "print(both_vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3a269f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(151444,)\n",
      "made one-hot labels of shape:\n",
      "(151444, 2)\n"
     ]
    }
   ],
   "source": [
    "#model 3\n",
    "#打乱顺序 result结果设为0 onehot labels\n",
    "sample_len = int(both_vectors.shape[0]/2)\n",
    "results0 = np.zeros(sample_len)\n",
    "results1 = np.ones(sample_len)\n",
    "results = np.concatenate((results0,results1),axis = 0)\n",
    "print(results.shape)\n",
    "\n",
    "results_oppo = np.concatenate((results1,results0),axis = 0)\n",
    "results_onehot = np.concatenate((results[:,np.newaxis],results_oppo[:,np.newaxis]),axis = 1)\n",
    "print(\"made one-hot labels of shape:\")\n",
    "print(results_onehot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47e11831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation dataset shape: (2000, 72, 32)\n",
      "validation target shape: (2000, 2)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "val_size_half = 1000\n",
    "v1 = both_vectors[0:val_size_half]\n",
    "v2 = both_vectors[151443-val_size_half:151443]\n",
    "val_data = np.concatenate((v1,v2),axis = 0)\n",
    "t1 = results_onehot[0:val_size_half]\n",
    "t2 = results_onehot[151443-val_size_half:151443]\n",
    "val_target = np.concatenate((t1,t2),axis = 0)\n",
    "print(\"validation dataset shape:\",val_data.shape)\n",
    "print(\"validation target shape:\",val_target.shape)\n",
    "val_dataset_onehot = Data.TensorDataset(torch.from_numpy(val_data), torch.from_numpy(val_target))\n",
    "#创建一个dataloader类的实例\n",
    "val_loader_onehot = Data.DataLoader(\n",
    "    # 从数据库中每次抽出batch size个样本\n",
    "    dataset=val_dataset_onehot,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c020e6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model 4 get subset dataloader of samples\n",
    "feed_size_half = 40000\n",
    "start = sample_len-feed_size_half\n",
    "end = feed_size_half+sample_len\n",
    "#print(start,end)\n",
    "batch_size = 32\n",
    "small_dataset_onehot = Data.TensorDataset(torch.from_numpy(both_vectors[start:end]), torch.from_numpy(results_onehot[start:end]))\n",
    "#创建一个dataloader类的实例\n",
    "small_loader_onehot = Data.DataLoader(\n",
    "    # 从数据库中每次抽出batch size个样本\n",
    "    dataset=small_dataset_onehot,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b827fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0897afb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599d7ee5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4796e41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################\n",
    "# ensenmble bi-lstm model\n",
    "sequence_length = 32\n",
    "input_size = 32 #emebedding vector feature\n",
    "hidden_size = 128 #hidden_size = 128 works for 10000data，acc=65\n",
    "num_layers = 3\n",
    "num_classes = 2\n",
    "batch_size = 32\n",
    "num_epochs = 100\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd256fe3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ed02a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "class subBRNN(nn.Module):\n",
    "    def _init_lstm(self, weight):\n",
    "        for w in weight.chunk(4, 0):\n",
    "            nn.init.xavier_uniform_(w)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(subBRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size, hidden_size, num_layers, batch_first=True, bidirectional=True\n",
    "        )\n",
    "        \n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size)\n",
    "        c0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size)\n",
    "\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = out[:, -1, :]\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4a994e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6482b7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyEnsemble(nn.Module):\n",
    "    def __init__(self, modelA, modelB, input_len,nb_classes=2):\n",
    "        super(MyEnsemble, self).__init__()\n",
    "        #self.bn1 = nn.BatchNorm1d(sequence_length)\n",
    "        #self.bn2 = nn.BatchNorm1d(sequence_length)\n",
    "        self.ln1 = torch.nn.LayerNorm([sequence_length,input_size],elementwise_affine=False)\n",
    "        \n",
    "        self.ln2 = torch.nn.LayerNorm([sequence_length,input_size],elementwise_affine=False)\n",
    "        \n",
    "        \n",
    "        self.modelA = modelA\n",
    "        self.modelB = modelB\n",
    "        \n",
    "        self.bn3 = nn.BatchNorm1d(nb_classes)\n",
    "        \n",
    "        # Create new classifier\n",
    "        self.classifier = nn.Linear(hidden_size*4, hidden_size)\n",
    "        self.dropout1 = nn.Dropout(p = 0.3)\n",
    "        self.classifier2 = nn.Linear(hidden_size, nb_classes)\n",
    "        self.dropout2 = nn.Dropout(p = 0.3)\n",
    "        \n",
    "        nn.init.xavier_uniform_(self.classifier.weight,gain=math.sqrt(2.0))\n",
    "        nn.init.xavier_uniform_(self.classifier2.weight,gain=math.sqrt(2.0))\n",
    "        #linear两层会经常输出全相同\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, xa,xb):\n",
    "        #xa = self.ln1(xa)\n",
    "        #xb = self.ln2(xb)\n",
    "        #xa = self.bn1(xa)\n",
    "        #xb = self.bn2(xb)\n",
    "        x1 = self.modelA(xa)  # condition\n",
    "        \n",
    "        x2 = self.modelB(xb)  # raise\n",
    "        \n",
    "        x_con = torch.cat((x1, x2), dim=1)\n",
    "        #print(\"x_con\",x_con.shape)\n",
    "        \n",
    "        \n",
    "        #x = self.classifier(F.leaky_relu_(x_con))\n",
    "        x_c1 = self.classifier(x_con)\n",
    "        #x_c1 = self.bn(x_c1)\n",
    "        x_c1 = self.dropout1(x_c1)\n",
    "        x_c2 = self.classifier2(x_c1)\n",
    "        x_c2 = self.dropout2(x_c2)\n",
    "        #return F.log_softmax(x,dim=-1)\n",
    "        #x_c2 = self.bn3(x_c2)\n",
    "        \n",
    "        return x_c2\n",
    "    \n",
    "modelA = subBRNN(input_size, hidden_size, num_layers, num_classes)\n",
    "modelB = subBRNN(input_size, hidden_size, num_layers, num_classes)\n",
    "model = MyEnsemble(modelA, modelB,hidden_size * 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7823ed40",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Step [512/0], Loss: 0.6931\n",
      "Epoch [1/100], Step [1024/0], Loss: 0.6932\n",
      "Epoch [1/100], Step [1536/0], Loss: 0.6931\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [29]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     36\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mfloat() \n\u001b[0;32m     37\u001b[0m targets \u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39mfloat() \n\u001b[1;32m---> 41\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m#print(\"scores\",scores)\u001b[39;00m\n\u001b[0;32m     44\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(scores, targets)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[1;32mIn [26]\u001b[0m, in \u001b[0;36mMyEnsemble.forward\u001b[1;34m(self, xa, xb)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, xa,xb):\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;66;03m#xa = self.ln1(xa)\u001b[39;00m\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;66;03m#xb = self.ln2(xb)\u001b[39;00m\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;66;03m#xa = self.bn1(xa)\u001b[39;00m\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;66;03m#xb = self.bn2(xb)\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m     x1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodelA\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxa\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# condition\u001b[39;00m\n\u001b[0;32m     36\u001b[0m     x2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodelB(xb)  \u001b[38;5;66;03m# raise\u001b[39;00m\n\u001b[0;32m     38\u001b[0m     x_con \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((x1, x2), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36msubBRNN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     28\u001b[0m h0 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m, x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size)\n\u001b[0;32m     29\u001b[0m c0 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m, x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size)\n\u001b[1;32m---> 31\u001b[0m out, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mh0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc0\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m out \u001b[38;5;241m=\u001b[39m out[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m#print(\"out\",out)\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m#print(\"out\",out.shape)\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m#shape 32x64  input_size(feature) , hidden_sizex2\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m#out = self.fc(out)\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:761\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    759\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_forward_args(\u001b[38;5;28minput\u001b[39m, hx, batch_sizes)\n\u001b[0;32m    760\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 761\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    762\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    763\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    764\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[0;32m    765\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train double Network !!!!!!!!!!!!!!\n",
    "\n",
    "# 定义loss和optimizer\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "val_losses = []\n",
    "val_acces = []\n",
    "losses = []\n",
    "acces = []\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay= weight_decay)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    correct = torch.zeros(1)\n",
    "    total = torch.zeros(1)\n",
    "    sum_loss = torch.zeros(1)\n",
    "    batches = torch.zeros(1)\n",
    "    #each epoch learn different sub-dataset\n",
    "    '''\n",
    "    if(epoch%4==0):\n",
    "        loader = subloader1\n",
    "    elif(epoch%4==1):\n",
    "        loader = subloader2\n",
    "    elif(epoch%4==2):\n",
    "        loader = subloader3\n",
    "    else:\n",
    "        loader = subloader4\n",
    "    \n",
    "    '''\n",
    "    #loader = subloaders[epoch%9]\n",
    "    for batch_idx, (data, targets) in enumerate(small_loader_onehot):#80000  #small_loader_onehot loader 20000 ,loader80k\n",
    "        # Get data to cuda if possible\n",
    "        #data = data.to(device=device).squeeze(1)\n",
    "        #targets = targets.to(device=device)\n",
    "        \n",
    "        # forward\n",
    "        data = data.float() \n",
    "        targets = targets.float() \n",
    "        \n",
    "        \n",
    "        \n",
    "        scores = model(data[:,0:16,:],data[:,32:32+20,:])\n",
    "        #print(\"scores\",scores)\n",
    "        \n",
    "        loss = criterion(scores, targets)\n",
    "        #loss=F.nll_loss(scores,targets)\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # gradient descent or adam step\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        \n",
    "        if (batch_idx+1) % 512 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, batch_idx+1, 0, loss.item()))\n",
    "            #print(scores)\n",
    "            \n",
    "        prediction = torch.argmax(scores,dim=1)\n",
    "        #bce entropy\n",
    "        curr_correct = (prediction == targets[:,1]).sum().float()\n",
    "        \n",
    "        #cross entropy \n",
    "        #curr_correct = (prediction == targets).sum().float()\n",
    "        \n",
    "        correct += curr_correct                \n",
    "        total += len(targets)\n",
    "        sum_loss += loss.item()\n",
    "        batches += 1\n",
    "        if(False):\n",
    "            if(batch_idx<7):\n",
    "                print(\"prediction\")\n",
    "                print(prediction)\n",
    "        \n",
    "        if(False):\n",
    "           \n",
    "            print(\"prediction\",prediction)\n",
    "            print(\"targets\",targets[:,1])\n",
    "            print(\"score\",scores)\n",
    "            print(\"curr_correct\",curr_correct)\n",
    "        \n",
    "    #validation-------------------------------------------------------------------------------------\n",
    "    model.eval()\n",
    "    val_loss_sum = torch.zeros(1)\n",
    "    val_batches = torch.zeros(1)\n",
    "    val_correct = torch.zeros(1)\n",
    "    val_total = torch.zeros(1)\n",
    "    #val_acc_sum = 0.0\n",
    "    for val_step,  (val_data, val_targets) in enumerate(val_loader_onehot, 1):\n",
    "        with torch.no_grad():\n",
    "            val_data = val_data.float() \n",
    "            val_targets = val_targets.float()\n",
    "            val_scores = model(val_data[:,0:16,:],val_data[:,32:32+20,:])\n",
    "            val_loss = criterion(val_scores, val_targets)\n",
    "            \n",
    "            val_prediction = torch.argmax(val_scores,dim=1)\n",
    "            valcurr_correct = (val_prediction == val_targets[:,1]).sum().float()\n",
    "        val_correct += valcurr_correct     \n",
    "        val_loss_sum += val_loss.item()\n",
    "        val_batches += 1\n",
    "        val_total += len(val_targets)\n",
    "        \n",
    "    #record--------------------------------------------------------------------------------------\n",
    "    val_acces.append((val_correct/val_total).cpu().detach().data.numpy())\n",
    "    val_acc_str = 'Accuracy: %f'%((val_correct/val_total).cpu().detach().data.numpy())\n",
    "    print(val_acc_str) \n",
    "    val_losses.append((val_loss_sum/val_batches).cpu().detach().data.numpy())\n",
    "    val_loss_str = 'Mean Validation Loss:: %f'%((val_loss_sum/val_batches).cpu().detach().data.numpy())\n",
    "    print(val_loss_str)      \n",
    "    acces.append((correct/total).cpu().detach().data.numpy())  \n",
    "    acc_str = 'Accuracy: %f'%((correct/total).cpu().detach().data.numpy())\n",
    "    print(acc_str)\n",
    "    loss_str = 'Mean loss: %f'%((sum_loss/batches).cpu().detach().data.numpy())\n",
    "    print(loss_str)\n",
    "    losses.append((sum_loss/batches).cpu().detach().data.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7137e0a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500aeeea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
